{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOx+jL4ATZYms+2espFYSZc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Dd3zR4dzfyz4"},"outputs":[],"source":["##Re-read last lecture (Tree decisions)\n","\n","#Test Condition: Ordinal\n","#-The test condition for an ordinal attribute can also be expressed (cont)\n","\n","#Test condition: Ordinal (Binary Split)\n","#Order must be maintained. We must do it in order to make sure it is an ordinal attribute\n","#Ex: small medium large (small medium one side) (large the other)\n","\n","#Continuous\n","#-Specify the test condition for a continuous attribute\n","#- We need to use discretization\n","#To discretize a continous attribute, we need to complete two subtasks:\n","#  -Decide how many categories to have?\n","#  - How to map the values to these categories\n","\n","#Discritization\n","#- The number of categories depends on the specific task\n","#- Suppose divided into n categorizes (intervals). n-1 split points are required. (cont)\n","\n","#Suppose Age is in [10,40] and 2 categorizes.\n","#Common approaches: Equal width and equal frequency, also K means for plotting data\n","#The equal width approach: each interval has the same width: [10,25], [25,40]\n","#The equal frequency approach : each interval has the same number of objects [10,22] etc cont\n","\n","#Specify the test condiition for a continuous attribute\n","#- The test condition for a continuous attribute can be expressed in two ways: multi-way split and binary split\n","#- n-categories discretization produces a n-way outcome\n","#- binary discretization produces two outcomes\n","\n","#Concerns\n","#-Determine how to split the records\n","#-How to specify the attribute test condition- done\n","#- How to determine the best split- current problem\n","#- Determine when to stop splitting\n","\n","#Suppose that we have a dataset and it has 20 objects that belong to two classes, class 0 and class 1.\n","#Before splitting, suppose that each class has 10 records.\n","#- 10 records of class 0\n","#- 10 records of class 1\n","#-Let C0 and C1 denote the class label of class 0 and class 1, respectively\n","\n","#Three splits of the dataset\n","#First picture- own car splits the dataset into two subsets and each subset has 10 objects\n","#- Left subset, 6 records belong to class 0 and 4 records in class 1\n","#- right subset, numbers are flipped\n","#Second- \"Car Type\"\n","#first subset, 1 record belonds to c0 and 3 records belong to class 1 (cont)\n","#Third picture, the test conidtion of \"Student ID\"\n","#Each subset, the object belongs to either C0 and C1.\n","#Can we evaluate the goodness of the split and which one is the best\n","\n","#A terminology: the class distribution- p(i/t) for node t\n","#-Probability of i given that we are in node t (often written as p(i))\n","#-Fraction of records belonging to class i at a node t.\n","#- In a two-class problem, the class distribution is written as \n","#(p(),p(1)) where p1 = 1-p()\n","#Example:\n","#In this node, there are 10 objects\n","#9.10 belong to c0, so p(co) = 0.9\n","#cont\n","\n","#This is important for probability of classes to evaluate the impurity of the nodes\n","#How to calculate to impurity- entrophy- maximum uncertainity in two class for 0.5 split\n","\n","#Node impurity\n","#Degree of the node impurity:\n","#The smaller the degree of impurity, the more skewed the class distribution.\n","#Used to evaluate a split.\n","\n","#Gini Index\n","#1-Sigma(p(i))*(t)**2 or 1- the sum of their squares or 1- (p(0)**2 + p(1)**2) where class 0 is 2/3 and class 1 is 1/3 should equal 0.444\n","\n","#Entropy\n","#-Sigma(p(i))(t)log2pi(t) the sum of the probability times the log of the probability so (p(0)log(p0)) + (p(1)log(p1)) so with the same above it is (2/3 log 2/3) + (1/3 log 1/3)\n","\n","#Misclassification error\n","#  1 - max[p(i)(t)] or 1- the max probability or 1 - max(2/3,1/3) which is 2/3 so 1-2/3 equals 1/3\n","\n","#Midterm is not on stuff we did in the last two classes, but the formulas can still show up where they were in those classes.\n","#Make sure to use log based on class numbers, so for this example we use log 2\n","\n","##Exercise- Calculating node impurity\n","#Node n1 class 0 = 0, class 1 = 6, class 0 P = 0, class 1 P = 1\n","#Node n2 class 0 = 1, class 2 = 5, class 0 P = 0.166666, class 1 = 0.8333333\n","#Node n3 class 0 = 3, class 1 = 3, class 0 P = 0.5, class 1 P = 0.5\n","\n","#Node 1 Gini - 0\n","#Node 2 Gini - 0.69444 + 0.027777 = 0.722222 (1 - 0.722222) = 0.277778\n","#Node 3 Gini - 0.5\n","\n","#Node 1 Entropy - 0\n","#Node 2 Entropy - 0.65\n","#Node 3 Entropy - 1\n","\n","#Node 1 Misclassification- 1- 1 = 0\n","#Node 2 Misclassification- 1 - 0.69444 = 0.30556\n","#Node 3 Misclassification- 1 - 0.5 = 0.5\n","\n","#Figure 4.13 compares the calues of the impurity measures for binary classifcation problems. p refers to the fraction of records that belong to one of the two classes\n","#Observe that all three measures attain their maximum value when the class distribution is uniform (i.e., when p = 0.5). The minimum values for the measures are attained when\n","#all the records belong to the same class (i.e., when p equals 0 or 1).\n","\n","#Monday- Midterm schwartz 156 on monday- bring a calculator- there will be calculations\n","\n","\n"]}]}